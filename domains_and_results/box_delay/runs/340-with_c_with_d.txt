RUN N=340 With=True
NB_BALL= 2
INITIAL STATES
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
|| robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_human = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
|| robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
|| robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
|| robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
|| robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
|| robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
|| robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
|| robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
|| human_init.at_robot = place1
|| human_init.at_human = place1
|| human_init.at_bucket = place1
|| human_init.nb_bucket = 2
|| human_init.nb_box1 = 1
|| human_init.nb_box2 = 0
|| human_init.nb_box3 = 0
|| human_init.stick_box1 = False
|| human_init.stick_box2 = False
|| human_init.stick_box3 = False
|| human_init.box1_sent = False
|| human_init.box2_sent = False
|| human_init.box3_sent = False
|________________________________________________________________________
Start first exploration
SA: human assessed stick_box1 <- True
first node = 0.0 Flag.E Type.I#1, (human BEGIN []) -1> (human BEGIN []) prev=None next=[]

<@> picked node = 0.0 Flag.E Type.I#1, (human BEGIN []) -1> (human BEGIN []) prev=None next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 2
||human_init.nb_box1 = 1
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 0-RA-task()
decomp i= 0 : origin
	0-RA-task() => [3-RA-prepare('box1',)] : dec_task_b1
s=False b=True b_r=True
	3-RA-prepare('box1',) => [4-RP-add_ball('box1',)-0.0 - 5-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	origin: [4-RP-add_ball('box1',)-0.0 - 5-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 6-RP-add_ball('box1',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-5-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [7-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 7-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	7-HA-prepare('box1',) => [8-HP-get_more()-0.0 - 9-HP-back_refill()-0.0 - 10-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [11-HP-send('box1',)-0.0, 12-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
human- Refine agenda with r_beliefs
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [13-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 13-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	13-HA-prepare('box1',) => [14-HP-get_more()-0.0 - 15-HP-back_refill()-0.0 - 16-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [17-HP-send('box1',)-0.0, 18-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [8-HP-get_more()-0.0 - 9-HP-back_refill()-0.0 - 10-HA-task()]
	dec_H_box_done_send: [11-HP-send('box1',)-0.0 - 12-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 19-HP-get_more()-1.0
	- 20-HP-send('box1',)-1.0

=> end explo
node explored = 1.0 Flag.F Type.H#1, (human BEGIN []) -2> (robot add_ball ('box1',)) prev=None next=[#2 #3]
new_e_flagged_nodes : 
	2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
e_flagged_nodes :
	2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
Ns before check = None
Nf = None
Ns after check = None
e_flagged_nodes after check solution:
	2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]

<@> picked node = 2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-5-RA-task()
| AGENDA human =
||	-9-HP-back_refill()-0.0
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 5-RA-task()
decomp i= 0 : dec_H_need_refill
	5-RA-task() => [21-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	21-RA-prepare('box1',) => [22-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	22-RA-prepare('box2',) => [23-RP-add_ball('box2',)-0.0 - 24-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [23-RP-add_ball('box2',)-0.0 - 24-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 25-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-24-RA-task()
| AGENDA human =
||	-9-HP-back_refill()-0.0
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 9-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 9-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [9-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed nb_bucket <- 10
applied refinement = 
next actions:
	- 26-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-24-RA-task()
| AGENDA human =
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 24-RA-task()
decomp i= 0 : dec_H_need_refill
	24-RA-task() => [27-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	27-RA-prepare('box1',) => [28-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	28-RA-prepare('box2',) => [29-RP-add_ball('box2',)-0.0 - 30-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [29-RP-add_ball('box2',)-0.0 - 30-RA-task()]
]
Decomp OK
Not same effects
modifs_human_with_h_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=0->1
modifs_human_with_r_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=0->2
modifs_robot_with_h_beliefs=
	- nb_bucket[None]=10->9
modifs_robot_with_r_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=1->2

# UPDATE belief divergences
	nb_box2:None: H=0 R=1

Testing with 1 relevant divergence
divergence tested = nb_box2:None: H=0 R=1
Task to refine: 10-HA-task()
decomp i= 0 : 
	10-HA-task() => [31-HA-prepare('box1',)] : dec_task_b1
	31-HA-prepare('box1',) => [32-HP-send('box1',)-0.0 - 33-HA-task()] : dec_H_box_done_send
	end 0
	divergence is relevant!
Relevant divergences to correct : 	nb_box2:None: H=0 R=1

COM: com action added eff = 34-RP-COM_ALIGN['nb_box2-1']-3.0
robot- Refine agenda
Task to refine: 24-RA-task()
decomp i= 0 : dec_H_need_refill
	24-RA-task() => [35-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	35-RA-prepare('box1',) => [36-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	36-RA-prepare('box2',) => [37-RP-add_ball('box2',)-0.0 - 38-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [37-RP-add_ball('box2',)-0.0 - 38-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
Trying to create delaying branch
rel_divs= 	nb_box2:None: H=0 R=1

	div not initial!
		testing n= 4.0 Flag.E Type.I#2, (human get_more ()) -3> (robot COM_ALIGN ['nb_box2-1']) prev=#1 next=[]
	div node identified :  4.0 Flag.E Type.I#2, (human get_more ()) -3> (robot COM_ALIGN ['nb_box2-1']) prev=#1 next=[]
	testing action= 19-HP-get_more()-1.0
		R-Agenda in [5-RA-task()]
		H-Agenda in [9-HP-back_refill()-0.0, 10-HA-task()]
before acting
after acting
__________________________________________________________________________
| AGENDA robot =
||	-5-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
after other
__________________________________________________________________________
| AGENDA robot =
||	-5-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
action.next= [25-RP-add_ball('box2',)-1.0]
	testing action= 25-RP-add_ball('box2',)-1.0
		R-Agenda in [24-RA-task()]
		H-Agenda in [9-HP-back_refill()-0.0, 10-HA-task()]
before acting
after acting
__________________________________________________________________________
| AGENDA robot =
||	-5-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
after other
__________________________________________________________________________
| AGENDA robot =
||	-5-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
agendas:
div_action.agent_agendas[CM.g_human_name]= [9-HP-back_refill()-0.0, 10-HA-task()]
div_action.agent_agendas[CM.g_robot_name]= [24-RA-task()]
	div action identified :  25-RP-add_ball('box2',)-1.0
__________________________________________________________________________
| AGENDA robot =
||	-25-RP-add_ball('box2',)-1.0
||	-24-RA-task()
| AGENDA human =
||	-9-HP-back_refill()-0.0
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
	Branching:
BRANCHING current_cost= 4.0
	div_node_bottom created =>  4.0 Flag.E Type.I#4, (robot add_ball ('box2',)) -2> (robot COM_ALIGN ['nb_box2-1']) prev=#2 next=[]
	delay_node created =>  2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	div_node edited =>  2.0 Flag.F Type.R#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[#4 #5]
applied refinement = 
next actions:
	- 39-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-38-RA-task()
| AGENDA human =
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 10-HA-task()
decomp i= 0 : dec_H_need_refill
	10-HA-task() => [41-HA-prepare('box1',)] : dec_task_b1
	41-HA-prepare('box1',) => [42-HP-send('box1',)-0.0 - 43-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 10-HA-task()
decomp i= 0 : dec_H_need_refill
	10-HA-task() => [44-HA-prepare('box1',)] : dec_task_b1
	44-HA-prepare('box1',) => [45-HP-send('box1',)-0.0 - 46-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [42-HP-send('box1',)-0.0 - 43-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 47-HP-send('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-38-RA-task()
| AGENDA human =
||	-43-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 38-RA-task()
decomp i= 0 : dec_H_need_refill
	38-RA-task() => [48-RA-prepare('box2',)] : dec_task_b2
s=True b=False b_r=True
	48-RA-prepare('box2',) => [49-RP-add_sticker('box2',)-0.0 - 50-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [49-RP-add_sticker('box2',)-0.0 - 50-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 51-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-50-RA-task()
| AGENDA human =
||	-43-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 43-HA-task()
decomp i= 0 : dec_H_need_refill
	43-HA-task() => [52-HA-prepare('box2',)] : dec_task_b2
	52-HA-prepare('box2',) => [53-HP-send('box2',)-0.0 - 54-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 43-HA-task()
decomp i= 0 : dec_H_need_refill
	43-HA-task() => [55-HA-prepare('box2',)] : dec_task_b2
	55-HA-prepare('box2',) => [56-HP-send('box2',)-0.0 - 57-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [53-HP-send('box2',)-0.0 - 54-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 58-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-50-RA-task()
| AGENDA human =
||	-54-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 50-RA-task()
decomp i= 0 : dec_H_need_refill
	50-RA-task() => [59-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	59-RA-prepare('box3',) => [60-RP-add_ball('box3',)-0.0 - 61-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [60-RP-add_ball('box3',)-0.0 - 61-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 62-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-61-RA-task()
| AGENDA human =
||	-54-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 54-HA-task()
decomp i= 0 : dec_H_need_refill
	54-HA-task() => [63-HA-prepare('box3',)] : dec_task_b3
	63-HA-prepare('box3',) => [64-HP-add_ball('box3',)-0.0 - 65-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 54-HA-task()
decomp i= 0 : dec_H_need_refill
	54-HA-task() => [66-HA-prepare('box3',)] : dec_task_b3
	66-HA-prepare('box3',) => [67-HP-add_ball('box3',)-0.0 - 68-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [64-HP-add_ball('box3',)-0.0 - 65-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 69-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-61-RA-task()
| AGENDA human =
||	-65-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 61-RA-task()
decomp i= 0 : dec_H_need_refill
	61-RA-task() => [70-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	70-RA-prepare('box3',) => [71-RP-add_sticker('box3',)-0.0 - 72-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [71-RP-add_sticker('box3',)-0.0 - 72-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 73-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-72-RA-task()
| AGENDA human =
||	-65-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 65-HA-task()
decomp i= 0 : dec_H_need_refill
	65-HA-task() => [74-HA-prepare('box3',)] : dec_task_b3
	74-HA-prepare('box3',) => [75-HP-send('box3',)-0.0 - 76-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 65-HA-task()
decomp i= 0 : dec_H_need_refill
	65-HA-task() => [77-HA-prepare('box3',)] : dec_task_b3
	77-HA-prepare('box3',) => [78-HP-send('box3',)-0.0 - 79-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [75-HP-send('box3',)-0.0 - 76-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 80-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-72-RA-task()
| AGENDA human =
||	-76-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 72-RA-task()
decomp i= 0 : dec_H_need_refill
	72-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	72-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_need_refill: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 81-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-76-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 76-HA-task()
decomp i= 0 : dec_H_need_refill
	76-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	76-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 76-HA-task()
decomp i= 0 : dec_H_need_refill
	76-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	76-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 2.0 Flag.F Type.R#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[#4 #5]
new_e_flagged_nodes : 
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	12.0 Flag.E Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes :
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	12.0 Flag.E Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
Ns before check = None
Nf = 12.0 Flag.E Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
new Ns!
Ns after check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes after check solution:
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]

<@> picked node = 2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-5-RA-task()
| AGENDA human =
||	-12-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 5-RA-task()
decomp i= 0 : dec_H_box_done_send
	5-RA-task() => [82-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=True
	82-RA-prepare('box2',) => [83-RP-add_ball('box2',)-0.0 - 84-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [83-RP-add_ball('box2',)-0.0 - 84-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 85-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-84-RA-task()
| AGENDA human =
||	-12-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 12-HA-task()
decomp i= 0 : dec_H_box_done_send
	12-HA-task() => [86-HA-prepare('box2',)] : dec_task_b2
	86-HA-prepare('box2',) => [87-HP-get_more()-0.0 - 88-HP-back_refill()-0.0 - 89-HA-task()] : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 12-HA-task()
decomp i= 0 : dec_H_box_done_send
	12-HA-task() => [90-HA-prepare('box2',)] : dec_task_b2
	90-HA-prepare('box2',) => [91-HP-get_more()-0.0 - 92-HP-back_refill()-0.0 - 93-HA-task()] : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [87-HP-get_more()-0.0 - 88-HP-back_refill()-0.0 - 89-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 94-HP-get_more()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-84-RA-task()
| AGENDA human =
||	-88-HP-back_refill()-0.0
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 84-RA-task()
decomp i= 0 : dec_H_box_done_send
	84-RA-task() => [95-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=False
	95-RA-prepare('box2',) => [96-RP-add_sticker('box2',)-0.0 - 97-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [96-RP-add_sticker('box2',)-0.0 - 97-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 98-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-97-RA-task()
| AGENDA human =
||	-88-HP-back_refill()-0.0
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 88-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 88-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [88-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed stick_box2 <- True
applied refinement = 
next actions:
	- 99-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-97-RA-task()
| AGENDA human =
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 97-RA-task()
decomp i= 0 : dec_H_box_done_send
	97-RA-task() => [100-RA-prepare('box2',)] : dec_task_b2
s=False b=True b_r=True
	100-RA-prepare('box2',) => [101-RP-add_ball('box2',)-0.0 - 102-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [101-RP-add_ball('box2',)-0.0 - 102-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 103-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-102-RA-task()
| AGENDA human =
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 89-HA-task()
decomp i= 0 : dec_H_box_done_send
	89-HA-task() => [104-HA-prepare('box2',)] : dec_task_b2
	104-HA-prepare('box2',) => [105-HP-send('box2',)-0.0 - 106-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 89-HA-task()
decomp i= 0 : dec_H_box_done_send
	89-HA-task() => [107-HA-prepare('box2',)] : dec_task_b2
	107-HA-prepare('box2',) => [108-HP-send('box2',)-0.0 - 109-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [105-HP-send('box2',)-0.0 - 106-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 110-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-102-RA-task()
| AGENDA human =
||	-106-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 102-RA-task()
decomp i= 0 : dec_H_box_done_send
	102-RA-task() => [111-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	111-RA-prepare('box3',) => [112-RP-add_ball('box3',)-0.0 - 113-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [112-RP-add_ball('box3',)-0.0 - 113-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 114-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-113-RA-task()
| AGENDA human =
||	-106-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 106-HA-task()
decomp i= 0 : dec_H_box_done_send
	106-HA-task() => [115-HA-prepare('box3',)] : dec_task_b3
	115-HA-prepare('box3',) => [116-HP-add_ball('box3',)-0.0 - 117-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 106-HA-task()
decomp i= 0 : dec_H_box_done_send
	106-HA-task() => [118-HA-prepare('box3',)] : dec_task_b3
	118-HA-prepare('box3',) => [119-HP-add_ball('box3',)-0.0 - 120-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [116-HP-add_ball('box3',)-0.0 - 117-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 121-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-113-RA-task()
| AGENDA human =
||	-117-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 113-RA-task()
decomp i= 0 : dec_H_box_done_send
	113-RA-task() => [122-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	122-RA-prepare('box3',) => [123-RP-add_sticker('box3',)-0.0 - 124-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [123-RP-add_sticker('box3',)-0.0 - 124-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 125-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-124-RA-task()
| AGENDA human =
||	-117-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 117-HA-task()
decomp i= 0 : dec_H_box_done_send
	117-HA-task() => [126-HA-prepare('box3',)] : dec_task_b3
	126-HA-prepare('box3',) => [127-HP-send('box3',)-0.0 - 128-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 117-HA-task()
decomp i= 0 : dec_H_box_done_send
	117-HA-task() => [129-HA-prepare('box3',)] : dec_task_b3
	129-HA-prepare('box3',) => [130-HP-send('box3',)-0.0 - 131-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [127-HP-send('box3',)-0.0 - 128-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 132-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-124-RA-task()
| AGENDA human =
||	-128-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 124-RA-task()
decomp i= 0 : dec_H_box_done_send
	124-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	124-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_box_done_send: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 133-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-128-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 128-HA-task()
decomp i= 0 : dec_H_box_done_send
	128-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	128-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 128-HA-task()
decomp i= 0 : dec_H_box_done_send
	128-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	128-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
new_e_flagged_nodes : 
	12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes :
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
Ns before check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
Nf = 12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
Ns after check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes after check solution:
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]

<@> picked node = 2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-25-RP-add_ball('box2',)-1.0
||	-24-RA-task()
| AGENDA human =
||	-9-HP-back_refill()-0.0
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 9-HP-back_refill()-0.0
decomp i= 0 : delaying
	end 0
human- Refine agenda with r_beliefs
Task to refine: 9-HP-back_refill()-0.0
decomp i= 0 : delaying
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [9-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 134-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-25-RP-add_ball('box2',)-1.0
||	-24-RA-task()
| AGENDA human =
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 11 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 11
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 25-RP-add_ball('box2',)-1.0
decomp i= 0 : delaying
	end 0
refinement = 
[
	delaying: [25-RP-add_ball('box2',)-1.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 135-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-24-RA-task()
| AGENDA human =
||	-10-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 10-HA-task()
decomp i= 0 : delaying
	10-HA-task() => [136-HA-prepare('box1',)] : dec_task_b1
	136-HA-prepare('box1',) => [137-HP-send('box1',)-0.0 - 138-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 10-HA-task()
decomp i= 0 : delaying
	10-HA-task() => [139-HA-prepare('box1',)] : dec_task_b1
	139-HA-prepare('box1',) => [140-HP-send('box1',)-0.0 - 141-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [137-HP-send('box1',)-0.0 - 138-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 142-HP-send('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-24-RA-task()
| AGENDA human =
||	-138-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 24-RA-task()
decomp i= 0 : delaying
	24-RA-task() => [143-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=True
	143-RA-prepare('box2',) => [144-RP-add_ball('box2',)-0.0 - 145-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	delaying: [144-RP-add_ball('box2',)-0.0 - 145-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 146-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-145-RA-task()
| AGENDA human =
||	-138-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 138-HA-task()
decomp i= 0 : delaying
	138-HA-task() => [147-HA-prepare('box2',)] : dec_task_b2
	147-HA-prepare('box2',) => DecompType.NO_APPLICABLE_METHOD
	end 0
human- Refine agenda with r_beliefs
Task to refine: 138-HA-task()
decomp i= 0 : delaying
	138-HA-task() => [148-HA-prepare('box2',)] : dec_task_b2
	148-HA-prepare('box2',) => DecompType.NO_APPLICABLE_METHOD
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [DecompType.NO_APPLICABLE_METHOD]
]
NO_APPLICABLE_METHOD => WAIT added
applied refinement = 
next actions:
	- 149-HP-WAIT[]-2.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-145-RA-task()
| AGENDA human =
||	-147-HA-prepare('box2',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 145-RA-task()
decomp i= 0 : delaying
	145-RA-task() => [150-RA-prepare('box2',)] : dec_task_b2
s=True b=False b_r=True
	150-RA-prepare('box2',) => [151-RP-add_sticker('box2',)-0.0 - 152-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	delaying: [151-RP-add_sticker('box2',)-0.0 - 152-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 153-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-152-RA-task()
| AGENDA human =
||	-147-HA-prepare('box2',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 147-HA-prepare('box2',)
decomp i= 0 : delaying
	147-HA-prepare('box2',) => [154-HP-send('box2',)-0.0 - 155-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 147-HA-prepare('box2',)
decomp i= 0 : delaying
	147-HA-prepare('box2',) => [156-HP-send('box2',)-0.0 - 157-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [154-HP-send('box2',)-0.0 - 155-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 158-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-152-RA-task()
| AGENDA human =
||	-155-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 152-RA-task()
decomp i= 0 : delaying
	152-RA-task() => [159-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	159-RA-prepare('box3',) => [160-RP-add_ball('box3',)-0.0 - 161-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	delaying: [160-RP-add_ball('box3',)-0.0 - 161-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 162-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-161-RA-task()
| AGENDA human =
||	-155-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 155-HA-task()
decomp i= 0 : delaying
	155-HA-task() => [163-HA-prepare('box3',)] : dec_task_b3
	163-HA-prepare('box3',) => [164-HP-add_ball('box3',)-0.0 - 165-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 155-HA-task()
decomp i= 0 : delaying
	155-HA-task() => [166-HA-prepare('box3',)] : dec_task_b3
	166-HA-prepare('box3',) => [167-HP-add_ball('box3',)-0.0 - 168-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [164-HP-add_ball('box3',)-0.0 - 165-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 169-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-161-RA-task()
| AGENDA human =
||	-165-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 161-RA-task()
decomp i= 0 : delaying
	161-RA-task() => [170-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	170-RA-prepare('box3',) => [171-RP-add_sticker('box3',)-0.0 - 172-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	delaying: [171-RP-add_sticker('box3',)-0.0 - 172-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 173-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-172-RA-task()
| AGENDA human =
||	-165-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 165-HA-task()
decomp i= 0 : delaying
	165-HA-task() => [174-HA-prepare('box3',)] : dec_task_b3
	174-HA-prepare('box3',) => [175-HP-send('box3',)-0.0 - 176-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 165-HA-task()
decomp i= 0 : delaying
	165-HA-task() => [177-HA-prepare('box3',)] : dec_task_b3
	177-HA-prepare('box3',) => [178-HP-send('box3',)-0.0 - 179-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [175-HP-send('box3',)-0.0 - 176-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 180-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-172-RA-task()
| AGENDA human =
||	-176-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 172-RA-task()
decomp i= 0 : delaying
	172-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	172-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	delaying: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 181-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-176-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 176-HA-task()
decomp i= 0 : delaying
	176-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	176-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 176-HA-task()
decomp i= 0 : delaying
	176-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	176-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
new_e_flagged_nodes : 
	14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes :
	14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
Ns before check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
Nf = 14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
Ns after check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes after check solution:
	=> time spent first exploration = 408ms

=> Start refining u nodes <=
	=> time spent refining = 0ms
Total duration = 408ms
Non relevant div:
False
Plans:
6-RP-add_ball('box1',)-1.0 19-HP-get_more()-1.0 25-RP-add_ball('box2',)-1.0 26-HP-back_refill()-1.0 34-RP-COM_ALIGN['nb_box2-1']-3.0 39-RP-add_ball('box2',)-1.0 47-HP-send('box1',)-1.0 51-RP-add_sticker('box2',)-1.0 58-HP-send('box2',)-1.0 62-RP-add_ball('box3',)-1.0 69-HP-add_ball('box3',)-1.0 73-RP-add_sticker('box3',)-1.0 80-HP-send('box3',)-1.0 81-RP-IDLE[]-0.0/6-RP-add_ball('box1',)-1.0 19-HP-get_more()-1.0 40-RP-DELAY[]-0.0 134-HP-back_refill()-1.0 135-RP-add_ball('box2',)-1.0 142-HP-send('box1',)-1.0 146-RP-add_ball('box2',)-1.0 149-HP-WAIT[]-2.0 153-RP-add_sticker('box2',)-1.0 158-HP-send('box2',)-1.0 162-RP-add_ball('box3',)-1.0 169-HP-add_ball('box3',)-1.0 173-RP-add_sticker('box3',)-1.0 180-HP-send('box3',)-1.0 181-RP-IDLE[]-0.0/6-RP-add_ball('box1',)-1.0 20-HP-send('box1',)-1.0 85-RP-add_ball('box2',)-1.0 94-HP-get_more()-1.0 98-RP-add_sticker('box2',)-1.0 99-HP-back_refill()-1.0 103-RP-add_ball('box2',)-1.0 110-HP-send('box2',)-1.0 114-RP-add_ball('box3',)-1.0 121-HP-add_ball('box3',)-1.0 125-RP-add_sticker('box3',)-1.0 132-HP-send('box3',)-1.0 133-RP-IDLE[]-0.0
best_traces:
[81-RP-IDLE[]-0.0, 133-RP-IDLE[]-0.0]
best_metrics:
(0.5, 0.0, 13.0, 0.0)
