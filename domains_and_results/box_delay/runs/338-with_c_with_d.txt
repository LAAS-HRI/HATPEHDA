RUN N=338 With=True
NB_BALL= 2
INITIAL STATES
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
|| robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_human = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
|| robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
|| robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
|| robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
|| robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
|| robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
|| robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
|| robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
|| human_init.at_robot = place1
|| human_init.at_human = place1
|| human_init.at_bucket = place1
|| human_init.nb_bucket = 2
|| human_init.nb_box1 = 0
|| human_init.nb_box2 = 0
|| human_init.nb_box3 = 0
|| human_init.stick_box1 = False
|| human_init.stick_box2 = False
|| human_init.stick_box3 = False
|| human_init.box1_sent = False
|| human_init.box2_sent = False
|| human_init.box3_sent = False
|________________________________________________________________________
Start first exploration
SA: human assessed stick_box1 <- True
first node = 0.0 Flag.E Type.I#1, (human BEGIN []) -1> (human BEGIN []) prev=None next=[]

<@> picked node = 0.0 Flag.E Type.I#1, (human BEGIN []) -1> (human BEGIN []) prev=None next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 2
||human_init.nb_box1 = 0
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 0-RA-task()
decomp i= 0 : origin
	0-RA-task() => [3-RA-prepare('box1',)] : dec_task_b1
s=False b=True b_r=True
	3-RA-prepare('box1',) => [4-RP-add_ball('box1',)-0.0 - 5-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	origin: [4-RP-add_ball('box1',)-0.0 - 5-RA-task()]
]
Decomp OK
Not same effects
modifs_human_with_h_beliefs=
	- nb_bucket[None]=2->1
	- nb_box1[None]=0->1
modifs_human_with_r_beliefs=
	- nb_bucket[None]=2->1
	- nb_box1[None]=0->2
modifs_robot_with_h_beliefs=
	- nb_bucket[None]=2->1
modifs_robot_with_r_beliefs=
	- nb_bucket[None]=2->1
	- nb_box1[None]=1->2

# UPDATE belief divergences
	nb_box1:None: H=0 R=1

Testing with 1 relevant divergence
divergence tested = nb_box1:None: H=0 R=1
Task to refine: 1-HA-task()
decomp i= 0 : 
	1-HA-task() => [6-HA-prepare('box1',)] : dec_task_b1
	6-HA-prepare('box1',) => [7-HP-add_ball('box1',)-0.0 - 8-HA-task()] : dec_H_missing_ball
	end 0
	divergence is relevant!
Relevant divergences to correct : 	nb_box1:None: H=0 R=1

COM: com action added eff = 9-RP-COM_ALIGN['nb_box1-1']-3.0
robot- Refine agenda
Task to refine: 0-RA-task()
decomp i= 0 : origin
	0-RA-task() => [10-RA-prepare('box1',)] : dec_task_b1
s=False b=True b_r=True
	10-RA-prepare('box1',) => [11-RP-add_ball('box1',)-0.0 - 12-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	origin: [11-RP-add_ball('box1',)-0.0 - 12-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
Trying to create delaying branch
rel_divs= 	nb_box1:None: H=0 R=1

	initial div ..
applied refinement = 
next actions:
	- 13-RP-add_ball('box1',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [14-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 14-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	14-HA-prepare('box1',) => [15-HP-get_more()-0.0 - 16-HP-back_refill()-0.0 - 17-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [18-HP-send('box1',)-0.0, 19-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
human- Refine agenda with r_beliefs
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [20-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 20-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	20-HA-prepare('box1',) => [21-HP-get_more()-0.0 - 22-HP-back_refill()-0.0 - 23-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [24-HP-send('box1',)-0.0, 25-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [15-HP-get_more()-0.0 - 16-HP-back_refill()-0.0 - 17-HA-task()]
	dec_H_box_done_send: [18-HP-send('box1',)-0.0 - 19-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 26-HP-get_more()-1.0
	- 27-HP-send('box1',)-1.0

=> end explo
node explored = 1.0 Flag.F Type.H#1, (human BEGIN []) -2> (robot add_ball ('box1',)) prev=None next=[#2 #3]
new_e_flagged_nodes : 
	2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
e_flagged_nodes :
	2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
Ns before check = None
Nf = None
Ns after check = None
e_flagged_nodes after check solution:
	2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]

<@> picked node = 2.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 12-RA-task()
decomp i= 0 : dec_H_need_refill
	12-RA-task() => [28-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	28-RA-prepare('box1',) => [29-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	29-RA-prepare('box2',) => [30-RP-add_ball('box2',)-0.0 - 31-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [30-RP-add_ball('box2',)-0.0 - 31-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 32-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [16-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed nb_bucket <- 10
applied refinement = 
next actions:
	- 33-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 31-RA-task()
decomp i= 0 : dec_H_need_refill
	31-RA-task() => [34-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	34-RA-prepare('box1',) => [35-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	35-RA-prepare('box2',) => [36-RP-add_ball('box2',)-0.0 - 37-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [36-RP-add_ball('box2',)-0.0 - 37-RA-task()]
]
Decomp OK
Not same effects
modifs_human_with_h_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=0->1
modifs_human_with_r_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=0->2
modifs_robot_with_h_beliefs=
	- nb_bucket[None]=10->9
modifs_robot_with_r_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=1->2

# UPDATE belief divergences
	nb_box2:None: H=0 R=1

Testing with 1 relevant divergence
divergence tested = nb_box2:None: H=0 R=1
Task to refine: 17-HA-task()
decomp i= 0 : 
	17-HA-task() => [38-HA-prepare('box1',)] : dec_task_b1
	38-HA-prepare('box1',) => [39-HP-send('box1',)-0.0 - 40-HA-task()] : dec_H_box_done_send
	end 0
	divergence is relevant!
Relevant divergences to correct : 	nb_box2:None: H=0 R=1

COM: com action added eff = 41-RP-COM_ALIGN['nb_box2-1']-3.0
robot- Refine agenda
Task to refine: 31-RA-task()
decomp i= 0 : dec_H_need_refill
	31-RA-task() => [42-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	42-RA-prepare('box1',) => [43-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	43-RA-prepare('box2',) => [44-RP-add_ball('box2',)-0.0 - 45-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [44-RP-add_ball('box2',)-0.0 - 45-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
Trying to create delaying branch
rel_divs= 	nb_box2:None: H=0 R=1

	div not initial!
		testing n= 4.0 Flag.E Type.I#2, (human get_more ()) -3> (robot COM_ALIGN ['nb_box2-1']) prev=#1 next=[]
	div node identified :  4.0 Flag.E Type.I#2, (human get_more ()) -3> (robot COM_ALIGN ['nb_box2-1']) prev=#1 next=[]
	testing action= 26-HP-get_more()-1.0
		R-Agenda in [12-RA-task()]
		H-Agenda in [16-HP-back_refill()-0.0, 17-HA-task()]
before acting
after acting
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
after other
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
action.next= [32-RP-add_ball('box2',)-1.0]
	testing action= 32-RP-add_ball('box2',)-1.0
		R-Agenda in [31-RA-task()]
		H-Agenda in [16-HP-back_refill()-0.0, 17-HA-task()]
before acting
after acting
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
after other
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
agendas:
div_action.agent_agendas[CM.g_human_name]= [16-HP-back_refill()-0.0, 17-HA-task()]
div_action.agent_agendas[CM.g_robot_name]= [31-RA-task()]
	div action identified :  32-RP-add_ball('box2',)-1.0
__________________________________________________________________________
| AGENDA robot =
||	-32-RP-add_ball('box2',)-1.0
||	-31-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
	Branching:
BRANCHING current_cost= 4.0
	div_node_bottom created =>  4.0 Flag.E Type.I#4, (robot add_ball ('box2',)) -2> (robot COM_ALIGN ['nb_box2-1']) prev=#2 next=[]
	delay_node created =>  2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	div_node edited =>  2.0 Flag.F Type.R#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[#4 #5]
applied refinement = 
next actions:
	- 46-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-45-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 17-HA-task()
decomp i= 0 : dec_H_need_refill
	17-HA-task() => [48-HA-prepare('box1',)] : dec_task_b1
	48-HA-prepare('box1',) => [49-HP-send('box1',)-0.0 - 50-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 17-HA-task()
decomp i= 0 : dec_H_need_refill
	17-HA-task() => [51-HA-prepare('box1',)] : dec_task_b1
	51-HA-prepare('box1',) => [52-HP-send('box1',)-0.0 - 53-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [49-HP-send('box1',)-0.0 - 50-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 54-HP-send('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-45-RA-task()
| AGENDA human =
||	-50-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 45-RA-task()
decomp i= 0 : dec_H_need_refill
	45-RA-task() => [55-RA-prepare('box2',)] : dec_task_b2
s=True b=False b_r=True
	55-RA-prepare('box2',) => [56-RP-add_sticker('box2',)-0.0 - 57-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [56-RP-add_sticker('box2',)-0.0 - 57-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 58-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-57-RA-task()
| AGENDA human =
||	-50-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 50-HA-task()
decomp i= 0 : dec_H_need_refill
	50-HA-task() => [59-HA-prepare('box2',)] : dec_task_b2
	59-HA-prepare('box2',) => [60-HP-send('box2',)-0.0 - 61-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 50-HA-task()
decomp i= 0 : dec_H_need_refill
	50-HA-task() => [62-HA-prepare('box2',)] : dec_task_b2
	62-HA-prepare('box2',) => [63-HP-send('box2',)-0.0 - 64-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [60-HP-send('box2',)-0.0 - 61-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 65-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-57-RA-task()
| AGENDA human =
||	-61-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 57-RA-task()
decomp i= 0 : dec_H_need_refill
	57-RA-task() => [66-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	66-RA-prepare('box3',) => [67-RP-add_ball('box3',)-0.0 - 68-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [67-RP-add_ball('box3',)-0.0 - 68-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 69-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-68-RA-task()
| AGENDA human =
||	-61-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 61-HA-task()
decomp i= 0 : dec_H_need_refill
	61-HA-task() => [70-HA-prepare('box3',)] : dec_task_b3
	70-HA-prepare('box3',) => [71-HP-add_ball('box3',)-0.0 - 72-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 61-HA-task()
decomp i= 0 : dec_H_need_refill
	61-HA-task() => [73-HA-prepare('box3',)] : dec_task_b3
	73-HA-prepare('box3',) => [74-HP-add_ball('box3',)-0.0 - 75-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [71-HP-add_ball('box3',)-0.0 - 72-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 76-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-68-RA-task()
| AGENDA human =
||	-72-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 68-RA-task()
decomp i= 0 : dec_H_need_refill
	68-RA-task() => [77-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	77-RA-prepare('box3',) => [78-RP-add_sticker('box3',)-0.0 - 79-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [78-RP-add_sticker('box3',)-0.0 - 79-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 80-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-79-RA-task()
| AGENDA human =
||	-72-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 72-HA-task()
decomp i= 0 : dec_H_need_refill
	72-HA-task() => [81-HA-prepare('box3',)] : dec_task_b3
	81-HA-prepare('box3',) => [82-HP-send('box3',)-0.0 - 83-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 72-HA-task()
decomp i= 0 : dec_H_need_refill
	72-HA-task() => [84-HA-prepare('box3',)] : dec_task_b3
	84-HA-prepare('box3',) => [85-HP-send('box3',)-0.0 - 86-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [82-HP-send('box3',)-0.0 - 83-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 87-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-79-RA-task()
| AGENDA human =
||	-83-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 79-RA-task()
decomp i= 0 : dec_H_need_refill
	79-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	79-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_need_refill: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 88-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-83-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 83-HA-task()
decomp i= 0 : dec_H_need_refill
	83-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	83-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 83-HA-task()
decomp i= 0 : dec_H_need_refill
	83-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	83-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 2.0 Flag.F Type.R#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[#4 #5]
new_e_flagged_nodes : 
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	12.0 Flag.E Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes :
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	12.0 Flag.E Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
Ns before check = None
Nf = 12.0 Flag.E Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
new Ns!
Ns after check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes after check solution:
	2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]

<@> picked node = 2.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-19-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 12-RA-task()
decomp i= 0 : dec_H_box_done_send
	12-RA-task() => [89-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=True
	89-RA-prepare('box2',) => [90-RP-add_ball('box2',)-0.0 - 91-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [90-RP-add_ball('box2',)-0.0 - 91-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 92-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-91-RA-task()
| AGENDA human =
||	-19-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 19-HA-task()
decomp i= 0 : dec_H_box_done_send
	19-HA-task() => [93-HA-prepare('box2',)] : dec_task_b2
	93-HA-prepare('box2',) => [94-HP-get_more()-0.0 - 95-HP-back_refill()-0.0 - 96-HA-task()] : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 19-HA-task()
decomp i= 0 : dec_H_box_done_send
	19-HA-task() => [97-HA-prepare('box2',)] : dec_task_b2
	97-HA-prepare('box2',) => [98-HP-get_more()-0.0 - 99-HP-back_refill()-0.0 - 100-HA-task()] : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [94-HP-get_more()-0.0 - 95-HP-back_refill()-0.0 - 96-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 101-HP-get_more()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-91-RA-task()
| AGENDA human =
||	-95-HP-back_refill()-0.0
||	-96-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 91-RA-task()
decomp i= 0 : dec_H_box_done_send
	91-RA-task() => [102-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=False
	102-RA-prepare('box2',) => [103-RP-add_sticker('box2',)-0.0 - 104-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [103-RP-add_sticker('box2',)-0.0 - 104-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 105-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-104-RA-task()
| AGENDA human =
||	-95-HP-back_refill()-0.0
||	-96-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 95-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 95-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [95-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed stick_box2 <- True
applied refinement = 
next actions:
	- 106-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-104-RA-task()
| AGENDA human =
||	-96-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 104-RA-task()
decomp i= 0 : dec_H_box_done_send
	104-RA-task() => [107-RA-prepare('box2',)] : dec_task_b2
s=False b=True b_r=True
	107-RA-prepare('box2',) => [108-RP-add_ball('box2',)-0.0 - 109-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [108-RP-add_ball('box2',)-0.0 - 109-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 110-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-109-RA-task()
| AGENDA human =
||	-96-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 96-HA-task()
decomp i= 0 : dec_H_box_done_send
	96-HA-task() => [111-HA-prepare('box2',)] : dec_task_b2
	111-HA-prepare('box2',) => [112-HP-send('box2',)-0.0 - 113-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 96-HA-task()
decomp i= 0 : dec_H_box_done_send
	96-HA-task() => [114-HA-prepare('box2',)] : dec_task_b2
	114-HA-prepare('box2',) => [115-HP-send('box2',)-0.0 - 116-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [112-HP-send('box2',)-0.0 - 113-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 117-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-109-RA-task()
| AGENDA human =
||	-113-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 109-RA-task()
decomp i= 0 : dec_H_box_done_send
	109-RA-task() => [118-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	118-RA-prepare('box3',) => [119-RP-add_ball('box3',)-0.0 - 120-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [119-RP-add_ball('box3',)-0.0 - 120-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 121-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-120-RA-task()
| AGENDA human =
||	-113-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 113-HA-task()
decomp i= 0 : dec_H_box_done_send
	113-HA-task() => [122-HA-prepare('box3',)] : dec_task_b3
	122-HA-prepare('box3',) => [123-HP-add_ball('box3',)-0.0 - 124-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 113-HA-task()
decomp i= 0 : dec_H_box_done_send
	113-HA-task() => [125-HA-prepare('box3',)] : dec_task_b3
	125-HA-prepare('box3',) => [126-HP-add_ball('box3',)-0.0 - 127-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [123-HP-add_ball('box3',)-0.0 - 124-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 128-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-120-RA-task()
| AGENDA human =
||	-124-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 120-RA-task()
decomp i= 0 : dec_H_box_done_send
	120-RA-task() => [129-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	129-RA-prepare('box3',) => [130-RP-add_sticker('box3',)-0.0 - 131-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [130-RP-add_sticker('box3',)-0.0 - 131-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 132-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-131-RA-task()
| AGENDA human =
||	-124-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 124-HA-task()
decomp i= 0 : dec_H_box_done_send
	124-HA-task() => [133-HA-prepare('box3',)] : dec_task_b3
	133-HA-prepare('box3',) => [134-HP-send('box3',)-0.0 - 135-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 124-HA-task()
decomp i= 0 : dec_H_box_done_send
	124-HA-task() => [136-HA-prepare('box3',)] : dec_task_b3
	136-HA-prepare('box3',) => [137-HP-send('box3',)-0.0 - 138-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [134-HP-send('box3',)-0.0 - 135-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 139-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-131-RA-task()
| AGENDA human =
||	-135-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 131-RA-task()
decomp i= 0 : dec_H_box_done_send
	131-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	131-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_box_done_send: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 140-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-135-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 135-HA-task()
decomp i= 0 : dec_H_box_done_send
	135-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	135-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 135-HA-task()
decomp i= 0 : dec_H_box_done_send
	135-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	135-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
new_e_flagged_nodes : 
	12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes :
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
	12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
Ns before check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
Nf = 12.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
Ns after check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes after check solution:
	2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]

<@> picked node = 2.0 Flag.E Type.D#5, (robot DELAY []) -1> (robot DELAY []) prev=#2 next=[]
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-32-RP-add_ball('box2',)-1.0
||	-31-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : delaying
	end 0
human- Refine agenda with r_beliefs
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : delaying
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [16-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 141-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-32-RP-add_ball('box2',)-1.0
||	-31-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 11 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 11
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 32-RP-add_ball('box2',)-1.0
decomp i= 0 : delaying
	end 0
refinement = 
[
	delaying: [32-RP-add_ball('box2',)-1.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 142-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 17-HA-task()
decomp i= 0 : delaying
	17-HA-task() => [143-HA-prepare('box1',)] : dec_task_b1
	143-HA-prepare('box1',) => [144-HP-send('box1',)-0.0 - 145-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 17-HA-task()
decomp i= 0 : delaying
	17-HA-task() => [146-HA-prepare('box1',)] : dec_task_b1
	146-HA-prepare('box1',) => [147-HP-send('box1',)-0.0 - 148-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [144-HP-send('box1',)-0.0 - 145-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 149-HP-send('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-145-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 31-RA-task()
decomp i= 0 : delaying
	31-RA-task() => [150-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=True
	150-RA-prepare('box2',) => [151-RP-add_ball('box2',)-0.0 - 152-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	delaying: [151-RP-add_ball('box2',)-0.0 - 152-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 153-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-152-RA-task()
| AGENDA human =
||	-145-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 145-HA-task()
decomp i= 0 : delaying
	145-HA-task() => [154-HA-prepare('box2',)] : dec_task_b2
	154-HA-prepare('box2',) => DecompType.NO_APPLICABLE_METHOD
	end 0
human- Refine agenda with r_beliefs
Task to refine: 145-HA-task()
decomp i= 0 : delaying
	145-HA-task() => [155-HA-prepare('box2',)] : dec_task_b2
	155-HA-prepare('box2',) => DecompType.NO_APPLICABLE_METHOD
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [DecompType.NO_APPLICABLE_METHOD]
]
NO_APPLICABLE_METHOD => WAIT added
applied refinement = 
next actions:
	- 156-HP-WAIT[]-2.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-152-RA-task()
| AGENDA human =
||	-154-HA-prepare('box2',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 152-RA-task()
decomp i= 0 : delaying
	152-RA-task() => [157-RA-prepare('box2',)] : dec_task_b2
s=True b=False b_r=True
	157-RA-prepare('box2',) => [158-RP-add_sticker('box2',)-0.0 - 159-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	delaying: [158-RP-add_sticker('box2',)-0.0 - 159-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 160-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-159-RA-task()
| AGENDA human =
||	-154-HA-prepare('box2',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 154-HA-prepare('box2',)
decomp i= 0 : delaying
	154-HA-prepare('box2',) => [161-HP-send('box2',)-0.0 - 162-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 154-HA-prepare('box2',)
decomp i= 0 : delaying
	154-HA-prepare('box2',) => [163-HP-send('box2',)-0.0 - 164-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [161-HP-send('box2',)-0.0 - 162-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 165-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-159-RA-task()
| AGENDA human =
||	-162-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 159-RA-task()
decomp i= 0 : delaying
	159-RA-task() => [166-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	166-RA-prepare('box3',) => [167-RP-add_ball('box3',)-0.0 - 168-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	delaying: [167-RP-add_ball('box3',)-0.0 - 168-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 169-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-168-RA-task()
| AGENDA human =
||	-162-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 162-HA-task()
decomp i= 0 : delaying
	162-HA-task() => [170-HA-prepare('box3',)] : dec_task_b3
	170-HA-prepare('box3',) => [171-HP-add_ball('box3',)-0.0 - 172-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 162-HA-task()
decomp i= 0 : delaying
	162-HA-task() => [173-HA-prepare('box3',)] : dec_task_b3
	173-HA-prepare('box3',) => [174-HP-add_ball('box3',)-0.0 - 175-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [171-HP-add_ball('box3',)-0.0 - 172-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 176-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-168-RA-task()
| AGENDA human =
||	-172-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 168-RA-task()
decomp i= 0 : delaying
	168-RA-task() => [177-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	177-RA-prepare('box3',) => [178-RP-add_sticker('box3',)-0.0 - 179-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	delaying: [178-RP-add_sticker('box3',)-0.0 - 179-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 180-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-179-RA-task()
| AGENDA human =
||	-172-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 172-HA-task()
decomp i= 0 : delaying
	172-HA-task() => [181-HA-prepare('box3',)] : dec_task_b3
	181-HA-prepare('box3',) => [182-HP-send('box3',)-0.0 - 183-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 172-HA-task()
decomp i= 0 : delaying
	172-HA-task() => [184-HA-prepare('box3',)] : dec_task_b3
	184-HA-prepare('box3',) => [185-HP-send('box3',)-0.0 - 186-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [182-HP-send('box3',)-0.0 - 183-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 187-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-179-RA-task()
| AGENDA human =
||	-183-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 179-RA-task()
decomp i= 0 : delaying
	179-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	179-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	delaying: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 188-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-183-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 183-HA-task()
decomp i= 0 : delaying
	183-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	183-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 183-HA-task()
decomp i= 0 : delaying
	183-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	183-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	delaying: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
new_e_flagged_nodes : 
	14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes :
	14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
Ns before check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
Nf = 14.0 Flag.E Type.F#5, (robot DELAY []) -13> (robot IDLE []) prev=#2 next=[]
Ns after check = 12.0 Flag.S Type.F#4, (robot add_ball ('box2',)) -11> (robot IDLE []) prev=#2 next=[]
e_flagged_nodes after check solution:
	=> time spent first exploration = 438ms

=> Start refining u nodes <=
	=> time spent refining = 0ms
Total duration = 438ms
Non relevant div:
False
Plans:
9-RP-COM_ALIGN['nb_box1-1']-3.0 13-RP-add_ball('box1',)-1.0 26-HP-get_more()-1.0 32-RP-add_ball('box2',)-1.0 33-HP-back_refill()-1.0 41-RP-COM_ALIGN['nb_box2-1']-3.0 46-RP-add_ball('box2',)-1.0 54-HP-send('box1',)-1.0 58-RP-add_sticker('box2',)-1.0 65-HP-send('box2',)-1.0 69-RP-add_ball('box3',)-1.0 76-HP-add_ball('box3',)-1.0 80-RP-add_sticker('box3',)-1.0 87-HP-send('box3',)-1.0 88-RP-IDLE[]-0.0/9-RP-COM_ALIGN['nb_box1-1']-3.0 13-RP-add_ball('box1',)-1.0 26-HP-get_more()-1.0 47-RP-DELAY[]-0.0 141-HP-back_refill()-1.0 142-RP-add_ball('box2',)-1.0 149-HP-send('box1',)-1.0 153-RP-add_ball('box2',)-1.0 156-HP-WAIT[]-2.0 160-RP-add_sticker('box2',)-1.0 165-HP-send('box2',)-1.0 169-RP-add_ball('box3',)-1.0 176-HP-add_ball('box3',)-1.0 180-RP-add_sticker('box3',)-1.0 187-HP-send('box3',)-1.0 188-RP-IDLE[]-0.0/9-RP-COM_ALIGN['nb_box1-1']-3.0 13-RP-add_ball('box1',)-1.0 27-HP-send('box1',)-1.0 92-RP-add_ball('box2',)-1.0 101-HP-get_more()-1.0 105-RP-add_sticker('box2',)-1.0 106-HP-back_refill()-1.0 110-RP-add_ball('box2',)-1.0 117-HP-send('box2',)-1.0 121-RP-add_ball('box3',)-1.0 128-HP-add_ball('box3',)-1.0 132-RP-add_sticker('box3',)-1.0 139-HP-send('box3',)-1.0 140-RP-IDLE[]-0.0
best_traces:
[88-RP-IDLE[]-0.0, 140-RP-IDLE[]-0.0]
best_metrics:
(1.5, 0.0, 13.0, 0.0)
