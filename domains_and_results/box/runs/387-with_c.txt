RUN N=387 With=True
NB_BALL= 3
INITIAL STATES
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
|| robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_human = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
|| robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
|| robot_init.nb_box1 = 0 	ObsType.INF 	loc=place1
|| robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
|| robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
|| robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
|| robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
|| human_init.at_robot = place1
|| human_init.at_human = place1
|| human_init.at_bucket = place1
|| human_init.nb_bucket = 2
|| human_init.nb_box1 = 0
|| human_init.nb_box2 = 0
|| human_init.nb_box3 = 0
|| human_init.stick_box1 = False
|| human_init.stick_box2 = False
|| human_init.stick_box3 = False
|| human_init.box1_sent = False
|| human_init.box2_sent = False
|| human_init.box3_sent = False
|________________________________________________________________________
Start first exploration
first node = 0.0 Flag.E Type.I#1, (robot BEGIN []) -1> (robot BEGIN []) prev=None next=[]

<@> picked node = 0.0 Flag.E Type.I#1, (robot BEGIN []) -1> (robot BEGIN []) prev=None next=[]
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 2
||human_init.nb_box1 = 0
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [3-HA-prepare('box1',)] : dec_task_b1
	3-HA-prepare('box1',) => [4-HP-add_ball('box1',)-0.0 - 5-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [6-HA-prepare('box1',)] : dec_task_b1
	6-HA-prepare('box1',) => [7-HP-add_ball('box1',)-0.0 - 8-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [4-HP-add_ball('box1',)-0.0 - 5-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 9-HP-add_ball('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-5-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 1
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 0-RA-task()
decomp i= 0 : origin
	0-RA-task() => [10-RA-prepare('box1',)] : dec_task_b1
s=True b=True b_r=True
	10-RA-prepare('box1',) => [11-RP-add_ball('box1',)-0.0 - 12-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	origin: [11-RP-add_ball('box1',)-0.0 - 12-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 13-RP-add_ball('box1',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-5-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 5-HA-task()
decomp i= 0 : origin
	5-HA-task() => [14-HA-prepare('box1',)] : dec_task_b1
	14-HA-prepare('box1',) => [15-HP-get_more()-0.0 - 16-HP-back_refill()-0.0 - 17-HA-task()] : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 5-HA-task()
decomp i= 0 : origin
	5-HA-task() => [18-HA-prepare('box1',)] : dec_task_b1
	18-HA-prepare('box1',) => [19-HP-get_more()-0.0 - 20-HP-back_refill()-0.0 - 21-HA-task()] : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [15-HP-get_more()-0.0 - 16-HP-back_refill()-0.0 - 17-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 22-HP-get_more()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 12-RA-task()
decomp i= 0 : origin
	12-RA-task() => [23-RA-prepare('box1',)] : dec_task_b1
s=True b=False b_r=False
	23-RA-prepare('box1',) => [24-RP-add_sticker('box1',)-0.0 - 25-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	origin: [24-RP-add_sticker('box1',)-0.0 - 25-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 26-RP-add_sticker('box1',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-25-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : origin
	end 0
human- Refine agenda with r_beliefs
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : origin
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [16-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed stick_box1 <- True
applied refinement = 
next actions:
	- 27-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-25-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 25-RA-task()
decomp i= 0 : origin
	25-RA-task() => [28-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	28-RA-prepare('box1',) => [29-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	29-RA-prepare('box2',) => [30-RP-add_ball('box2',)-0.0 - 31-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	origin: [30-RP-add_ball('box2',)-0.0 - 31-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 32-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 17-HA-task()
decomp i= 0 : origin
	17-HA-task() => [33-HA-prepare('box1',)] : dec_task_b1
	33-HA-prepare('box1',) => [34-HP-send('box1',)-0.0 - 35-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 17-HA-task()
decomp i= 0 : origin
	17-HA-task() => [36-HA-prepare('box1',)] : dec_task_b1
	36-HA-prepare('box1',) => [37-HP-send('box1',)-0.0 - 38-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [34-HP-send('box1',)-0.0 - 35-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 39-HP-send('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-35-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 31-RA-task()
decomp i= 0 : origin
	31-RA-task() => [40-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=True
	40-RA-prepare('box2',) => [41-RP-add_ball('box2',)-0.0 - 42-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	origin: [41-RP-add_ball('box2',)-0.0 - 42-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 43-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-42-RA-task()
| AGENDA human =
||	-35-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 35-HA-task()
decomp i= 0 : origin
	35-HA-task() => [44-HA-prepare('box2',)] : dec_task_b2
	44-HA-prepare('box2',) => DecompType.NO_APPLICABLE_METHOD
	end 0
human- Refine agenda with r_beliefs
Task to refine: 35-HA-task()
decomp i= 0 : origin
	35-HA-task() => [45-HA-prepare('box2',)] : dec_task_b2
	45-HA-prepare('box2',) => DecompType.NO_APPLICABLE_METHOD
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [DecompType.NO_APPLICABLE_METHOD]
]
NO_APPLICABLE_METHOD => WAIT added
applied refinement = 
next actions:
	- 46-HP-WAIT[]-2.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-42-RA-task()
| AGENDA human =
||	-44-HA-prepare('box2',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 42-RA-task()
decomp i= 0 : origin
	42-RA-task() => [47-RA-prepare('box2',)] : dec_task_b2
s=True b=False b_r=True
	47-RA-prepare('box2',) => [48-RP-add_sticker('box2',)-0.0 - 49-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	origin: [48-RP-add_sticker('box2',)-0.0 - 49-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 50-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-49-RA-task()
| AGENDA human =
||	-44-HA-prepare('box2',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 44-HA-prepare('box2',)
decomp i= 0 : origin
	44-HA-prepare('box2',) => [51-HP-send('box2',)-0.0 - 52-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 44-HA-prepare('box2',)
decomp i= 0 : origin
	44-HA-prepare('box2',) => [53-HP-send('box2',)-0.0 - 54-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [51-HP-send('box2',)-0.0 - 52-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 55-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-49-RA-task()
| AGENDA human =
||	-52-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 49-RA-task()
decomp i= 0 : origin
	49-RA-task() => [56-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	56-RA-prepare('box3',) => [57-RP-add_ball('box3',)-0.0 - 58-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	origin: [57-RP-add_ball('box3',)-0.0 - 58-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 59-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-58-RA-task()
| AGENDA human =
||	-52-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 52-HA-task()
decomp i= 0 : origin
	52-HA-task() => [60-HA-prepare('box3',)] : dec_task_b3
	60-HA-prepare('box3',) => [61-HP-add_ball('box3',)-0.0 - 62-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 52-HA-task()
decomp i= 0 : origin
	52-HA-task() => [63-HA-prepare('box3',)] : dec_task_b3
	63-HA-prepare('box3',) => [64-HP-add_ball('box3',)-0.0 - 65-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [61-HP-add_ball('box3',)-0.0 - 62-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 66-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-58-RA-task()
| AGENDA human =
||	-62-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 6 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 6
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 58-RA-task()
decomp i= 0 : origin
	58-RA-task() => [67-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	67-RA-prepare('box3',) => [68-RP-add_sticker('box3',)-0.0 - 69-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	origin: [68-RP-add_sticker('box3',)-0.0 - 69-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 70-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-69-RA-task()
| AGENDA human =
||	-62-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 6 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 6
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 62-HA-task()
decomp i= 0 : origin
	62-HA-task() => [71-HA-prepare('box3',)] : dec_task_b3
	71-HA-prepare('box3',) => [72-HP-send('box3',)-0.0 - 73-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 62-HA-task()
decomp i= 0 : origin
	62-HA-task() => [74-HA-prepare('box3',)] : dec_task_b3
	74-HA-prepare('box3',) => [75-HP-send('box3',)-0.0 - 76-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [72-HP-send('box3',)-0.0 - 73-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 77-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-69-RA-task()
| AGENDA human =
||	-73-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 6 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 6
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 69-RA-task()
decomp i= 0 : origin
	69-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	69-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	origin: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 78-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-73-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 6 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 6
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 73-HA-task()
decomp i= 0 : origin
	73-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	73-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 73-HA-task()
decomp i= 0 : origin
	73-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	73-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 16.0 Flag.E Type.F#1, (robot BEGIN []) -17> (robot IDLE []) prev=None next=[]
new_e_flagged_nodes : 
	16.0 Flag.E Type.F#1, (robot BEGIN []) -17> (robot IDLE []) prev=None next=[]
e_flagged_nodes :
	16.0 Flag.E Type.F#1, (robot BEGIN []) -17> (robot IDLE []) prev=None next=[]
Ns before check = None
Nf = 16.0 Flag.E Type.F#1, (robot BEGIN []) -17> (robot IDLE []) prev=None next=[]
new Ns!
Ns after check = 16.0 Flag.S Type.F#1, (robot BEGIN []) -17> (robot IDLE []) prev=None next=[]
e_flagged_nodes after check solution:
	=> time spent first exploration = 171ms

=> Start refining u nodes <=
	=> time spent refining = 0ms
Total duration = 171ms
Non relevant div:
False
Plans:
9-HP-add_ball('box1',)-1.0 13-RP-add_ball('box1',)-1.0 22-HP-get_more()-1.0 26-RP-add_sticker('box1',)-1.0 27-HP-back_refill()-1.0 32-RP-add_ball('box2',)-1.0 39-HP-send('box1',)-1.0 43-RP-add_ball('box2',)-1.0 46-HP-WAIT[]-2.0 50-RP-add_sticker('box2',)-1.0 55-HP-send('box2',)-1.0 59-RP-add_ball('box3',)-1.0 66-HP-add_ball('box3',)-1.0 70-RP-add_sticker('box3',)-1.0 77-HP-send('box3',)-1.0 78-RP-IDLE[]-0.0
best_traces:
[78-RP-IDLE[]-0.0]
best_metrics:
(0, 1, 16, 0)
