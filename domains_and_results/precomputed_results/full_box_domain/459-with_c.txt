RUN N=459 With=True
NB_BALL= 3
INITIAL STATES
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
|| robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_human = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
|| robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
|| robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
|| robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
|| robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
|| robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
|| robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
|| human_init.at_robot = place1
|| human_init.at_human = place1
|| human_init.at_bucket = place1
|| human_init.nb_bucket = 2
|| human_init.nb_box1 = 0
|| human_init.nb_box2 = 0
|| human_init.nb_box3 = 0
|| human_init.stick_box1 = True
|| human_init.stick_box2 = False
|| human_init.stick_box3 = False
|| human_init.box1_sent = False
|| human_init.box2_sent = False
|| human_init.box3_sent = False
|________________________________________________________________________
Start first exploration
SA: human assessed stick_box1 <- False
first node = 0.0 Flag.E Type.I#1, (robot BEGIN []) -1> (robot BEGIN []) prev=None next=[]

<@> picked node = 0.0 Flag.E Type.I#1, (robot BEGIN []) -1> (robot BEGIN []) prev=None next=[]
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 2
||human_init.nb_box1 = 0
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [3-HA-prepare('box1',)] : dec_task_b1
	3-HA-prepare('box1',) => [4-HP-add_ball('box1',)-0.0 - 5-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [6-HA-prepare('box1',)] : dec_task_b1
	6-HA-prepare('box1',) => [7-HP-add_ball('box1',)-0.0 - 8-HA-task()] : dec_H_missing_ball
	end 0
Not same effects
modifs_human_with_h_beliefs=
	- nb_bucket[None]=2->1
	- nb_box1[None]=0->1
modifs_human_with_r_beliefs=
	- nb_bucket[None]=2->1
	- nb_box1[None]=0->2
modifs_robot_with_h_beliefs=
	- nb_bucket[None]=2->1
modifs_robot_with_r_beliefs=
	- nb_bucket[None]=2->1
	- nb_box1[None]=1->2
NEED of belief alignment!

# UPDATE belief divergences
	nb_box1:None: H=0 R=1

Testing with 1 relevant divergence
divergence tested = nb_box1:None: H=0 R=1
Task to refine: 1-HA-task()
decomp i= 0 : 
	1-HA-task() => [9-HA-prepare('box1',)] : dec_task_b1
	9-HA-prepare('box1',) => [10-HP-add_ball('box1',)-0.0 - 11-HA-task()] : dec_H_missing_ball
	end 0
	divergence is relevant!
Relevant divergences to correct : 	nb_box1:None: H=0 R=1

COM: com action added = 12-RP-COM_ALIGN['nb_box1-None-1']-3.0
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [13-HA-prepare('box1',)] : dec_task_b1
	13-HA-prepare('box1',) => [14-HP-add_ball('box1',)-0.0 - 15-HA-task()] : dec_H_missing_ball
	end 0
refinement = 
[
	origin: [14-HP-add_ball('box1',)-0.0 - 15-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 16-HP-add_ball('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-15-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 0-RA-task()
decomp i= 0 : origin
	0-RA-task() => [17-RA-prepare('box1',)] : dec_task_b1
s=True b=False b_r=True
	17-RA-prepare('box1',) => [18-RP-add_sticker('box1',)-0.0 - 19-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	origin: [18-RP-add_sticker('box1',)-0.0 - 19-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 20-RP-add_sticker('box1',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-19-RA-task()
| AGENDA human =
||	-15-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 15-HA-task()
decomp i= 0 : origin
	15-HA-task() => [21-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 21-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	21-HA-prepare('box1',) => [22-HP-get_more()-0.0 - 23-HP-back_refill()-0.0 - 24-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [25-HP-send('box1',)-0.0, 26-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
human- Refine agenda with r_beliefs
Task to refine: 15-HA-task()
decomp i= 0 : origin
	15-HA-task() => [27-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 27-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	27-HA-prepare('box1',) => [28-HP-get_more()-0.0 - 29-HP-back_refill()-0.0 - 30-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [31-HP-send('box1',)-0.0, 32-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [22-HP-get_more()-0.0 - 23-HP-back_refill()-0.0 - 24-HA-task()]
	dec_H_box_done_send: [25-HP-send('box1',)-0.0 - 26-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 33-HP-get_more()-1.0
	- 34-HP-send('box1',)-1.0

=> end explo
node explored = 5.0 Flag.F Type.H#1, (robot BEGIN []) -3> (robot add_sticker ('box1',)) prev=None next=[#2 #3]
new_e_flagged_nodes : 
	6.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	6.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
e_flagged_nodes :
	6.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	6.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
Ns before check = None
Nf = None
Ns after check = None
e_flagged_nodes after check solution:
	6.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	6.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]

<@> picked node = 6.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-19-RA-task()
| AGENDA human =
||	-23-HP-back_refill()-0.0
||	-24-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 19-RA-task()
decomp i= 0 : dec_H_need_refill
	19-RA-task() => [35-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	35-RA-prepare('box1',) => [36-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	36-RA-prepare('box2',) => [37-RP-add_ball('box2',)-0.0 - 38-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [37-RP-add_ball('box2',)-0.0 - 38-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 39-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-38-RA-task()
| AGENDA human =
||	-23-HP-back_refill()-0.0
||	-24-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 23-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 23-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [23-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed nb_bucket <- 10
applied refinement = 
next actions:
	- 40-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-38-RA-task()
| AGENDA human =
||	-24-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 38-RA-task()
decomp i= 0 : dec_H_need_refill
	38-RA-task() => [41-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	41-RA-prepare('box1',) => [42-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	42-RA-prepare('box2',) => [43-RP-add_ball('box2',)-0.0 - 44-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [43-RP-add_ball('box2',)-0.0 - 44-RA-task()]
]
Decomp OK
Not same effects
modifs_human_with_h_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=0->1
modifs_human_with_r_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=0->2
modifs_robot_with_h_beliefs=
	- nb_bucket[None]=10->9
modifs_robot_with_r_beliefs=
	- nb_bucket[None]=10->9
	- nb_box2[None]=1->2

# UPDATE belief divergences
	nb_box2:None: H=0 R=1

Testing with 1 relevant divergence
divergence tested = nb_box2:None: H=0 R=1
Task to refine: 24-HA-task()
decomp i= 0 : 
	24-HA-task() => [45-HA-prepare('box1',)] : dec_task_b1
	45-HA-prepare('box1',) => [46-HP-send('box1',)-0.0 - 47-HA-task()] : dec_H_box_done_send
	end 0
	divergence is relevant!
Relevant divergences to correct : 	nb_box2:None: H=0 R=1

COM: com action added eff = 48-RP-COM_ALIGN['nb_box2-None-1']-3.0
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 49-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-44-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-24-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 24-HA-task()
decomp i= 0 : dec_H_need_refill
	24-HA-task() => [50-HA-prepare('box1',)] : dec_task_b1
	50-HA-prepare('box1',) => [51-HP-send('box1',)-0.0 - 52-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 24-HA-task()
decomp i= 0 : dec_H_need_refill
	24-HA-task() => [53-HA-prepare('box1',)] : dec_task_b1
	53-HA-prepare('box1',) => [54-HP-send('box1',)-0.0 - 55-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [51-HP-send('box1',)-0.0 - 52-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 56-HP-send('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-44-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-52-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 44-RA-task()
decomp i= 0 : dec_H_need_refill
	44-RA-task() => [57-RA-prepare('box2',)] : dec_task_b2
s=True b=False b_r=True
	57-RA-prepare('box2',) => [58-RP-add_sticker('box2',)-0.0 - 59-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [58-RP-add_sticker('box2',)-0.0 - 59-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 60-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-59-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-52-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 52-HA-task()
decomp i= 0 : dec_H_need_refill
	52-HA-task() => [61-HA-prepare('box2',)] : dec_task_b2
	61-HA-prepare('box2',) => [62-HP-send('box2',)-0.0 - 63-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 52-HA-task()
decomp i= 0 : dec_H_need_refill
	52-HA-task() => [64-HA-prepare('box2',)] : dec_task_b2
	64-HA-prepare('box2',) => [65-HP-send('box2',)-0.0 - 66-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [62-HP-send('box2',)-0.0 - 63-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 67-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-59-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-63-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 59-RA-task()
decomp i= 0 : dec_H_need_refill
	59-RA-task() => [68-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	68-RA-prepare('box3',) => [69-RP-add_ball('box3',)-0.0 - 70-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [69-RP-add_ball('box3',)-0.0 - 70-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 71-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-70-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-63-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 63-HA-task()
decomp i= 0 : dec_H_need_refill
	63-HA-task() => [72-HA-prepare('box3',)] : dec_task_b3
	72-HA-prepare('box3',) => [73-HP-add_ball('box3',)-0.0 - 74-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 63-HA-task()
decomp i= 0 : dec_H_need_refill
	63-HA-task() => [75-HA-prepare('box3',)] : dec_task_b3
	75-HA-prepare('box3',) => [76-HP-add_ball('box3',)-0.0 - 77-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [73-HP-add_ball('box3',)-0.0 - 74-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 78-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-70-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-74-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 70-RA-task()
decomp i= 0 : dec_H_need_refill
	70-RA-task() => [79-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	79-RA-prepare('box3',) => [80-RP-add_sticker('box3',)-0.0 - 81-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [80-RP-add_sticker('box3',)-0.0 - 81-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 82-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-81-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-74-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 74-HA-task()
decomp i= 0 : dec_H_need_refill
	74-HA-task() => [83-HA-prepare('box3',)] : dec_task_b3
	83-HA-prepare('box3',) => [84-HP-send('box3',)-0.0 - 85-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 74-HA-task()
decomp i= 0 : dec_H_need_refill
	74-HA-task() => [86-HA-prepare('box3',)] : dec_task_b3
	86-HA-prepare('box3',) => [87-HP-send('box3',)-0.0 - 88-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [84-HP-send('box3',)-0.0 - 85-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 89-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-81-RA-task()
||	-38-RA-task()
| AGENDA human =
||	-85-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 81-RA-task()
decomp i= 0 : dec_H_need_refill
	81-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	continue with next_task popped from agenda 38-RA-task()
	38-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	38-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_need_refill: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 90-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-85-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 85-HA-task()
decomp i= 0 : dec_H_need_refill
	85-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	85-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 85-HA-task()
decomp i= 0 : dec_H_need_refill
	85-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	85-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 19.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
new_e_flagged_nodes : 
	19.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes :
	6.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
	19.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
Ns before check = None
Nf = 19.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
new Ns!
Ns after check = 19.0 Flag.S Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes after check solution:
	6.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]

<@> picked node = 6.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-19-RA-task()
| AGENDA human =
||	-26-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 0 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 0
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 19-RA-task()
decomp i= 0 : dec_H_box_done_send
	19-RA-task() => [91-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=True
	91-RA-prepare('box2',) => [92-RP-add_ball('box2',)-0.0 - 93-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [92-RP-add_ball('box2',)-0.0 - 93-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 94-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-93-RA-task()
| AGENDA human =
||	-26-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 26-HA-task()
decomp i= 0 : dec_H_box_done_send
	26-HA-task() => [95-HA-prepare('box2',)] : dec_task_b2
	95-HA-prepare('box2',) => [96-HP-get_more()-0.0 - 97-HP-back_refill()-0.0 - 98-HA-task()] : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 26-HA-task()
decomp i= 0 : dec_H_box_done_send
	26-HA-task() => [99-HA-prepare('box2',)] : dec_task_b2
	99-HA-prepare('box2',) => [100-HP-get_more()-0.0 - 101-HP-back_refill()-0.0 - 102-HA-task()] : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [96-HP-get_more()-0.0 - 97-HP-back_refill()-0.0 - 98-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 103-HP-get_more()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-93-RA-task()
| AGENDA human =
||	-97-HP-back_refill()-0.0
||	-98-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 93-RA-task()
decomp i= 0 : dec_H_box_done_send
	93-RA-task() => [104-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=False
	104-RA-prepare('box2',) => [105-RP-add_sticker('box2',)-0.0 - 106-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [105-RP-add_sticker('box2',)-0.0 - 106-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 107-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-106-RA-task()
| AGENDA human =
||	-97-HP-back_refill()-0.0
||	-98-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 97-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 97-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [97-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed stick_box2 <- True
applied refinement = 
next actions:
	- 108-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-106-RA-task()
| AGENDA human =
||	-98-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 106-RA-task()
decomp i= 0 : dec_H_box_done_send
	106-RA-task() => [109-RA-prepare('box2',)] : dec_task_b2
s=False b=True b_r=True
	109-RA-prepare('box2',) => [110-RP-add_ball('box2',)-0.0 - 111-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [110-RP-add_ball('box2',)-0.0 - 111-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 112-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-111-RA-task()
| AGENDA human =
||	-98-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 98-HA-task()
decomp i= 0 : dec_H_box_done_send
	98-HA-task() => [113-HA-prepare('box2',)] : dec_task_b2
	113-HA-prepare('box2',) => [114-HP-send('box2',)-0.0 - 115-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 98-HA-task()
decomp i= 0 : dec_H_box_done_send
	98-HA-task() => [116-HA-prepare('box2',)] : dec_task_b2
	116-HA-prepare('box2',) => [117-HP-send('box2',)-0.0 - 118-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [114-HP-send('box2',)-0.0 - 115-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 119-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-111-RA-task()
| AGENDA human =
||	-115-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 111-RA-task()
decomp i= 0 : dec_H_box_done_send
	111-RA-task() => [120-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	120-RA-prepare('box3',) => [121-RP-add_ball('box3',)-0.0 - 122-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [121-RP-add_ball('box3',)-0.0 - 122-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 123-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-122-RA-task()
| AGENDA human =
||	-115-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 115-HA-task()
decomp i= 0 : dec_H_box_done_send
	115-HA-task() => [124-HA-prepare('box3',)] : dec_task_b3
	124-HA-prepare('box3',) => [125-HP-add_ball('box3',)-0.0 - 126-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 115-HA-task()
decomp i= 0 : dec_H_box_done_send
	115-HA-task() => [127-HA-prepare('box3',)] : dec_task_b3
	127-HA-prepare('box3',) => [128-HP-add_ball('box3',)-0.0 - 129-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [125-HP-add_ball('box3',)-0.0 - 126-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 130-HP-add_ball('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-122-RA-task()
| AGENDA human =
||	-126-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 122-RA-task()
decomp i= 0 : dec_H_box_done_send
	122-RA-task() => [131-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	131-RA-prepare('box3',) => [132-RP-add_sticker('box3',)-0.0 - 133-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [132-RP-add_sticker('box3',)-0.0 - 133-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 134-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-133-RA-task()
| AGENDA human =
||	-126-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 126-HA-task()
decomp i= 0 : dec_H_box_done_send
	126-HA-task() => [135-HA-prepare('box3',)] : dec_task_b3
	135-HA-prepare('box3',) => [136-HP-send('box3',)-0.0 - 137-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 126-HA-task()
decomp i= 0 : dec_H_box_done_send
	126-HA-task() => [138-HA-prepare('box3',)] : dec_task_b3
	138-HA-prepare('box3',) => [139-HP-send('box3',)-0.0 - 140-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [136-HP-send('box3',)-0.0 - 137-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 141-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-133-RA-task()
| AGENDA human =
||	-137-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 133-RA-task()
decomp i= 0 : dec_H_box_done_send
	133-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	133-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_box_done_send: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 142-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-137-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 7 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 7
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 137-HA-task()
decomp i= 0 : dec_H_box_done_send
	137-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	137-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 137-HA-task()
decomp i= 0 : dec_H_box_done_send
	137-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	137-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 16.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
new_e_flagged_nodes : 
	16.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes :
	16.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
Ns before check = 19.0 Flag.S Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
Nf = 16.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
new Ns!
Ns after check = 16.0 Flag.S Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes after check solution:
	=> time spent first exploration = 410ms

=> Start refining u nodes <=
	=> time spent refining = 0ms
Total duration = 410ms
Non relevant div:
False
Plans:
12-RP-COM_ALIGN['nb_box1-None-1']-3.0 16-HP-add_ball('box1',)-1.0 20-RP-add_sticker('box1',)-1.0 33-HP-get_more()-1.0 39-RP-add_ball('box2',)-1.0 40-HP-back_refill()-1.0 48-RP-COM_ALIGN['nb_box2-None-1']-3.0 49-RP-add_ball('box2',)-1.0 56-HP-send('box1',)-1.0 60-RP-add_sticker('box2',)-1.0 67-HP-send('box2',)-1.0 71-RP-add_ball('box3',)-1.0 78-HP-add_ball('box3',)-1.0 82-RP-add_sticker('box3',)-1.0 89-HP-send('box3',)-1.0 90-RP-IDLE[]-0.0/12-RP-COM_ALIGN['nb_box1-None-1']-3.0 16-HP-add_ball('box1',)-1.0 20-RP-add_sticker('box1',)-1.0 34-HP-send('box1',)-1.0 94-RP-add_ball('box2',)-1.0 103-HP-get_more()-1.0 107-RP-add_sticker('box2',)-1.0 108-HP-back_refill()-1.0 112-RP-add_ball('box2',)-1.0 119-HP-send('box2',)-1.0 123-RP-add_ball('box3',)-1.0 130-HP-add_ball('box3',)-1.0 134-RP-add_sticker('box3',)-1.0 141-HP-send('box3',)-1.0 142-RP-IDLE[]-0.0
