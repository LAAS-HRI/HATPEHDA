RUN N=487 With=True
NB_BALL= 3
INITIAL STATES
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
|| robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_human = place1 	ObsType.OBS 	loc=place1
|| robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
|| robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
|| robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
|| robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
|| robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
|| robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
|| robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
|| robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
|| robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
|| human_init.at_robot = place1
|| human_init.at_human = place1
|| human_init.at_bucket = place1
|| human_init.nb_bucket = 2
|| human_init.nb_box1 = 1
|| human_init.nb_box2 = 1
|| human_init.nb_box3 = 0
|| human_init.stick_box1 = False
|| human_init.stick_box2 = False
|| human_init.stick_box3 = False
|| human_init.box1_sent = False
|| human_init.box2_sent = False
|| human_init.box3_sent = False
|________________________________________________________________________
Start first exploration
first node = 0.0 Flag.E Type.I#1, (robot BEGIN []) -1> (robot BEGIN []) prev=None next=[]

<@> picked node = 0.0 Flag.E Type.I#1, (robot BEGIN []) -1> (robot BEGIN []) prev=None next=[]
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-1-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 2 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 2
||human_init.nb_box1 = 1
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [3-HA-prepare('box1',)] : dec_task_b1
	3-HA-prepare('box1',) => [4-HP-add_ball('box1',)-0.0 - 5-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 1-HA-task()
decomp i= 0 : origin
	1-HA-task() => [6-HA-prepare('box1',)] : dec_task_b1
	6-HA-prepare('box1',) => [7-HP-add_ball('box1',)-0.0 - 8-HA-task()] : dec_H_missing_ball
	end 0
No relevant belief divergence for refinement
refinement = 
[
	origin: [4-HP-add_ball('box1',)-0.0 - 5-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 9-HP-add_ball('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-0-RA-task()
| AGENDA human =
||	-5-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = False
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 0-RA-task()
decomp i= 0 : origin
	0-RA-task() => [10-RA-prepare('box1',)] : dec_task_b1
s=True b=False b_r=True
	10-RA-prepare('box1',) => [11-RP-add_sticker('box1',)-0.0 - 12-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	origin: [11-RP-add_sticker('box1',)-0.0 - 12-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 13-RP-add_sticker('box1',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-5-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 5-HA-task()
decomp i= 0 : origin
	5-HA-task() => [14-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 14-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	14-HA-prepare('box1',) => [15-HP-get_more()-0.0 - 16-HP-back_refill()-0.0 - 17-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [18-HP-send('box1',)-0.0, 19-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
human- Refine agenda with r_beliefs
Task to refine: 5-HA-task()
decomp i= 0 : origin
	5-HA-task() => [20-HA-prepare('box1',)] : dec_task_b1
	multiple decs for 20-HA-prepare('box1',):  dec_H_need_refill  dec_H_box_done_send 
	20-HA-prepare('box1',) => [21-HP-get_more()-0.0 - 22-HP-back_refill()-0.0 - 23-HA-task()] : dec_H_need_refill
		decomposition 1 : dec_H_box_done_send created : [24-HP-send('box1',)-0.0, 25-HA-task()]
	end 0
decomp i= 1 : dec_H_box_done_send
	end 1
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [15-HP-get_more()-0.0 - 16-HP-back_refill()-0.0 - 17-HA-task()]
	dec_H_box_done_send: [18-HP-send('box1',)-0.0 - 19-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 26-HP-get_more()-1.0
	- 27-HP-send('box1',)-1.0

=> end explo
node explored = 2.0 Flag.F Type.H#1, (robot BEGIN []) -3> (robot add_sticker ('box1',)) prev=None next=[#2 #3]
new_e_flagged_nodes : 
	3.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	3.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
e_flagged_nodes :
	3.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	3.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
Ns before check = None
Nf = None
Ns after check = None
e_flagged_nodes after check solution:
	3.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
	3.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]

<@> picked node = 3.0 Flag.E Type.I#2, (human get_more ()) -1> (human get_more ()) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 12-RA-task()
decomp i= 0 : dec_H_need_refill
	12-RA-task() => [28-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	28-RA-prepare('box1',) => [29-RA-prepare('box2',)] : dec_R_next_box
s=True b=True b_r=True
	29-RA-prepare('box2',) => [30-RP-add_ball('box2',)-0.0 - 31-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [30-RP-add_ball('box2',)-0.0 - 31-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 32-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-16-HP-back_refill()-0.0
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 16-HP-back_refill()-0.0
decomp i= 0 : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [16-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed nb_bucket <- 10
applied refinement = 
next actions:
	- 33-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-31-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 31-RA-task()
decomp i= 0 : dec_H_need_refill
	31-RA-task() => [34-RA-prepare('box1',)] : dec_task_b1
s=False b=False b_r=True
	34-RA-prepare('box1',) => [35-RA-prepare('box2',)] : dec_R_next_box
s=True b=False b_r=True
	35-RA-prepare('box2',) => [36-RP-add_sticker('box2',)-0.0 - 37-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [36-RP-add_sticker('box2',)-0.0 - 37-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 38-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-37-RA-task()
| AGENDA human =
||	-17-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = False
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 17-HA-task()
decomp i= 0 : dec_H_need_refill
	17-HA-task() => [39-HA-prepare('box1',)] : dec_task_b1
	39-HA-prepare('box1',) => [40-HP-send('box1',)-0.0 - 41-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 17-HA-task()
decomp i= 0 : dec_H_need_refill
	17-HA-task() => [42-HA-prepare('box1',)] : dec_task_b1
	42-HA-prepare('box1',) => [43-HP-send('box1',)-0.0 - 44-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [40-HP-send('box1',)-0.0 - 41-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 45-HP-send('box1',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-37-RA-task()
| AGENDA human =
||	-41-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 37-RA-task()
decomp i= 0 : dec_H_need_refill
	37-RA-task() => [46-RA-prepare('box2',)] : dec_task_b2
s=False b=False b_r=True
	46-RA-prepare('box2',) => [47-RA-prepare('box3',)] : dec_R_next_box
s=True b=True b_r=True
	47-RA-prepare('box3',) => [48-RP-add_ball('box3',)-0.0 - 49-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [48-RP-add_ball('box3',)-0.0 - 49-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 50-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-49-RA-task()
| AGENDA human =
||	-41-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 41-HA-task()
decomp i= 0 : dec_H_need_refill
	41-HA-task() => [51-HA-prepare('box2',)] : dec_task_b2
	51-HA-prepare('box2',) => [52-HP-add_ball('box2',)-0.0 - 53-HA-task()] : dec_H_missing_ball
	end 0
human- Refine agenda with r_beliefs
Task to refine: 41-HA-task()
decomp i= 0 : dec_H_need_refill
	41-HA-task() => [54-HA-prepare('box2',)] : dec_task_b2
	54-HA-prepare('box2',) => [55-HP-send('box2',)-0.0 - 56-HA-task()] : dec_H_box_done_send
	end 0
Not same task name
NEED of belief alignment!

# UPDATE belief divergences
	nb_box2:None: H=1 R=2

Testing with 1 relevant divergence
divergence tested = nb_box2:None: H=1 R=2
Task to refine: 41-HA-task()
decomp i= 0 : 
	41-HA-task() => [57-HA-prepare('box2',)] : dec_task_b2
	57-HA-prepare('box2',) => [58-HP-send('box2',)-0.0 - 59-HA-task()] : dec_H_box_done_send
	end 0
	divergence is relevant!
Relevant divergences to correct : 	nb_box2:None: H=1 R=2

COM: com action added = 60-RP-COM_ALIGN['nb_box2-None-2']-3.0
Task to refine: 41-HA-task()
decomp i= 0 : dec_H_need_refill
	41-HA-task() => [61-HA-prepare('box2',)] : dec_task_b2
	61-HA-prepare('box2',) => [62-HP-send('box2',)-0.0 - 63-HA-task()] : dec_H_box_done_send
	end 0
refinement = 
[
	dec_H_need_refill: [62-HP-send('box2',)-0.0 - 63-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 64-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-49-RA-task()
| AGENDA human =
||	-63-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 49-RA-task()
decomp i= 0 : dec_H_need_refill
	49-RA-task() => [65-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	65-RA-prepare('box3',) => [66-RP-add_ball('box3',)-0.0 - 67-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_need_refill: [66-RP-add_ball('box3',)-0.0 - 67-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 68-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-67-RA-task()
| AGENDA human =
||	-63-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 63-HA-task()
decomp i= 0 : dec_H_need_refill
	63-HA-task() => [69-HA-prepare('box3',)] : dec_task_b3
	69-HA-prepare('box3',) => DecompType.NO_APPLICABLE_METHOD
	end 0
human- Refine agenda with r_beliefs
Task to refine: 63-HA-task()
decomp i= 0 : dec_H_need_refill
	63-HA-task() => [70-HA-prepare('box3',)] : dec_task_b3
	70-HA-prepare('box3',) => DecompType.NO_APPLICABLE_METHOD
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [DecompType.NO_APPLICABLE_METHOD]
]
NO_APPLICABLE_METHOD => WAIT added
applied refinement = 
next actions:
	- 71-HP-WAIT[]-2.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-67-RA-task()
| AGENDA human =
||	-69-HA-prepare('box3',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 67-RA-task()
decomp i= 0 : dec_H_need_refill
	67-RA-task() => [72-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	72-RA-prepare('box3',) => [73-RP-add_sticker('box3',)-0.0 - 74-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_need_refill: [73-RP-add_sticker('box3',)-0.0 - 74-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 75-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-74-RA-task()
| AGENDA human =
||	-69-HA-prepare('box3',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 69-HA-prepare('box3',)
decomp i= 0 : dec_H_need_refill
	69-HA-prepare('box3',) => [76-HP-send('box3',)-0.0 - 77-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 69-HA-prepare('box3',)
decomp i= 0 : dec_H_need_refill
	69-HA-prepare('box3',) => [78-HP-send('box3',)-0.0 - 79-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [76-HP-send('box3',)-0.0 - 77-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 80-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-74-RA-task()
| AGENDA human =
||	-77-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 74-RA-task()
decomp i= 0 : dec_H_need_refill
	74-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	74-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_need_refill: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 81-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-77-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 77-HA-task()
decomp i= 0 : dec_H_need_refill
	77-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	77-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 77-HA-task()
decomp i= 0 : dec_H_need_refill
	77-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	77-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_need_refill: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 17.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
new_e_flagged_nodes : 
	17.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes :
	3.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
	17.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
Ns before check = None
Nf = 17.0 Flag.E Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
new Ns!
Ns after check = 17.0 Flag.S Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes after check solution:
	3.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]

<@> picked node = 3.0 Flag.E Type.I#3, (human send ('box1',)) -1> (human send ('box1',)) prev=#1 next=[]
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-12-RA-task()
| AGENDA human =
||	-19-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 1 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 1 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 1
||human_init.nb_box1 = 2
||human_init.nb_box2 = 1
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 12-RA-task()
decomp i= 0 : dec_H_box_done_send
	12-RA-task() => [82-RA-prepare('box2',)] : dec_task_b2
s=True b=True b_r=True
	82-RA-prepare('box2',) => [83-RP-add_ball('box2',)-0.0 - 84-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [83-RP-add_ball('box2',)-0.0 - 84-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 85-RP-add_ball('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-84-RA-task()
| AGENDA human =
||	-19-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 19-HA-task()
decomp i= 0 : dec_H_box_done_send
	19-HA-task() => [86-HA-prepare('box2',)] : dec_task_b2
	86-HA-prepare('box2',) => [87-HP-get_more()-0.0 - 88-HP-back_refill()-0.0 - 89-HA-task()] : dec_H_need_refill
	end 0
human- Refine agenda with r_beliefs
Task to refine: 19-HA-task()
decomp i= 0 : dec_H_box_done_send
	19-HA-task() => [90-HA-prepare('box2',)] : dec_task_b2
	90-HA-prepare('box2',) => [91-HP-get_more()-0.0 - 92-HP-back_refill()-0.0 - 93-HA-task()] : dec_H_need_refill
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [87-HP-get_more()-0.0 - 88-HP-back_refill()-0.0 - 89-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 94-HP-get_more()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-84-RA-task()
| AGENDA human =
||	-88-HP-back_refill()-0.0
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = False 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 84-RA-task()
decomp i= 0 : dec_H_box_done_send
	84-RA-task() => [95-RA-prepare('box2',)] : dec_task_b2
s=True b=False b_r=False
	95-RA-prepare('box2',) => [96-RP-add_sticker('box2',)-0.0 - 97-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [96-RP-add_sticker('box2',)-0.0 - 97-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 98-RP-add_sticker('box2',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-97-RA-task()
| AGENDA human =
||	-88-HP-back_refill()-0.0
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place2 	ObsType.OBS 	loc=place2
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 0 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place2
||human_init.at_bucket = place1
||human_init.nb_bucket = 0
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = False
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 88-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 88-HP-back_refill()-0.0
decomp i= 0 : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [88-HP-back_refill()-0.0]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
SA: human assessed stick_box2 <- True
applied refinement = 
next actions:
	- 99-HP-back_refill()-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-97-RA-task()
| AGENDA human =
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 10 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 0 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 10
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 0
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 97-RA-task()
decomp i= 0 : dec_H_box_done_send
	97-RA-task() => [100-RA-prepare('box2',)] : dec_task_b2
s=False b=False b_r=True
	100-RA-prepare('box2',) => [101-RA-prepare('box3',)] : dec_R_next_box
s=True b=True b_r=True
	101-RA-prepare('box3',) => [102-RP-add_ball('box3',)-0.0 - 103-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [102-RP-add_ball('box3',)-0.0 - 103-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 104-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-103-RA-task()
| AGENDA human =
||	-89-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = False 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = False
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 89-HA-task()
decomp i= 0 : dec_H_box_done_send
	89-HA-task() => [105-HA-prepare('box2',)] : dec_task_b2
	105-HA-prepare('box2',) => [106-HP-send('box2',)-0.0 - 107-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 89-HA-task()
decomp i= 0 : dec_H_box_done_send
	89-HA-task() => [108-HA-prepare('box2',)] : dec_task_b2
	108-HA-prepare('box2',) => [109-HP-send('box2',)-0.0 - 110-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [106-HP-send('box2',)-0.0 - 107-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 111-HP-send('box2',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-103-RA-task()
| AGENDA human =
||	-107-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 9 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 1 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 9
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 1
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 103-RA-task()
decomp i= 0 : dec_H_box_done_send
	103-RA-task() => [112-RA-prepare('box3',)] : dec_task_b3
s=True b=True b_r=True
	112-RA-prepare('box3',) => [113-RP-add_ball('box3',)-0.0 - 114-RA-task()] : dec_R_missing_ball
	end 0
refinement = 
[
	dec_H_box_done_send: [113-RP-add_ball('box3',)-0.0 - 114-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 115-RP-add_ball('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-114-RA-task()
| AGENDA human =
||	-107-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 107-HA-task()
decomp i= 0 : dec_H_box_done_send
	107-HA-task() => [116-HA-prepare('box3',)] : dec_task_b3
	116-HA-prepare('box3',) => DecompType.NO_APPLICABLE_METHOD
	end 0
human- Refine agenda with r_beliefs
Task to refine: 107-HA-task()
decomp i= 0 : dec_H_box_done_send
	107-HA-task() => [117-HA-prepare('box3',)] : dec_task_b3
	117-HA-prepare('box3',) => DecompType.NO_APPLICABLE_METHOD
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [DecompType.NO_APPLICABLE_METHOD]
]
NO_APPLICABLE_METHOD => WAIT added
applied refinement = 
next actions:
	- 118-HP-WAIT[]-2.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-114-RA-task()
| AGENDA human =
||	-116-HA-prepare('box3',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = False 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = False
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
robot- Refine agenda
Task to refine: 114-RA-task()
decomp i= 0 : dec_H_box_done_send
	114-RA-task() => [119-RA-prepare('box3',)] : dec_task_b3
s=True b=False b_r=True
	119-RA-prepare('box3',) => [120-RP-add_sticker('box3',)-0.0 - 121-RA-task()] : dec_R_missing_sticker
	end 0
refinement = 
[
	dec_H_box_done_send: [120-RP-add_sticker('box3',)-0.0 - 121-RA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 122-RP-add_sticker('box3',)-1.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-121-RA-task()
| AGENDA human =
||	-116-HA-prepare('box3',)
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = False 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = False
|________________________________________________________________________
human- Refine agenda
Task to refine: 116-HA-prepare('box3',)
decomp i= 0 : dec_H_box_done_send
	116-HA-prepare('box3',) => [123-HP-send('box3',)-0.0 - 124-HA-task()] : dec_H_box_done_send
	end 0
human- Refine agenda with r_beliefs
Task to refine: 116-HA-prepare('box3',)
decomp i= 0 : dec_H_box_done_send
	116-HA-prepare('box3',) => [125-HP-send('box3',)-0.0 - 126-HA-task()] : dec_H_box_done_send
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [123-HP-send('box3',)-0.0 - 124-HA-task()]
]
Decomp OK
apply acting agent
applicable with other's beliefs
Update other's beliefs
applied refinement = 
next actions:
	- 127-HP-send('box3',)-1.0

continue ..
=> R step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
||	-121-RA-task()
| AGENDA human =
||	-124-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
robot- Refine agenda
Task to refine: 121-RA-task()
decomp i= 0 : dec_H_box_done_send
	121-RA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	121-RA-task() => DecompType.AGENDA_EMPTY
	end 0
refinement = 
[
	dec_H_box_done_send: [DecompType.AGENDA_EMPTY]
]
AGENDA_EMPTY => IDLE added
applied refinement = 
next actions:
	- 128-RP-IDLE[]-0.0

continue ..
=> H step explo ==================================================================================
__________________________________________________________________________
| AGENDA robot =
| AGENDA human =
||	-124-HA-task()
|------------------------------------------------------------------------
| STATE robot =
||robot_init.at_robot = place1 	ObsType.OBS 	loc=place1
||robot_init.at_human = place1 	ObsType.OBS 	loc=place1
||robot_init.at_bucket = place1 	ObsType.OBS 	loc=place1
||robot_init.nb_bucket = 8 	ObsType.OBS 	loc=place1
||robot_init.nb_box1 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box2 = 2 	ObsType.INF 	loc=place1
||robot_init.nb_box3 = 2 	ObsType.INF 	loc=place1
||robot_init.stick_box1 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box2 = True 	ObsType.OBS 	loc=place1
||robot_init.stick_box3 = True 	ObsType.OBS 	loc=place1
||robot_init.box1_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box2_sent = True 	ObsType.OBS 	loc=place1
||robot_init.box3_sent = True 	ObsType.OBS 	loc=place1
| STATE human =
||human_init.at_robot = place1
||human_init.at_human = place1
||human_init.at_bucket = place1
||human_init.nb_bucket = 8
||human_init.nb_box1 = 2
||human_init.nb_box2 = 2
||human_init.nb_box3 = 2
||human_init.stick_box1 = True
||human_init.stick_box2 = True
||human_init.stick_box3 = True
||human_init.box1_sent = True
||human_init.box2_sent = True
||human_init.box3_sent = True
|________________________________________________________________________
human- Refine agenda
Task to refine: 124-HA-task()
decomp i= 0 : dec_H_box_done_send
	124-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	124-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
human- Refine agenda with r_beliefs
Task to refine: 124-HA-task()
decomp i= 0 : dec_H_box_done_send
	124-HA-task() => [] : dec_task_done
[92m	refines into nothing[0m
	124-HA-task() => DecompType.BOTH_AGENDAS_EMPTY
	end 0
No relevant belief divergence for refinement
refinement = 
[
	dec_H_box_done_send: [DecompType.BOTH_AGENDAS_EMPTY]
]
BOTH_AGENDAS_EMPTY
applied refinement = 
next actions:

=> end explo
node explored = 14.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
new_e_flagged_nodes : 
	14.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes :
	14.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
Ns before check = 17.0 Flag.S Type.F#2, (human get_more ()) -12> (robot IDLE []) prev=#1 next=[]
Nf = 14.0 Flag.E Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
new Ns!
Ns after check = 14.0 Flag.S Type.F#3, (human send ('box1',)) -12> (robot IDLE []) prev=#1 next=[]
e_flagged_nodes after check solution:
	=> time spent first exploration = 349ms

=> Start refining u nodes <=
	=> time spent refining = 0ms
Total duration = 349ms
Non relevant div:
False
Plans:
9-HP-add_ball('box1',)-1.0 13-RP-add_sticker('box1',)-1.0 26-HP-get_more()-1.0 32-RP-add_ball('box2',)-1.0 33-HP-back_refill()-1.0 38-RP-add_sticker('box2',)-1.0 45-HP-send('box1',)-1.0 50-RP-add_ball('box3',)-1.0 60-RP-COM_ALIGN['nb_box2-None-2']-3.0 64-HP-send('box2',)-1.0 68-RP-add_ball('box3',)-1.0 71-HP-WAIT[]-2.0 75-RP-add_sticker('box3',)-1.0 80-HP-send('box3',)-1.0 81-RP-IDLE[]-0.0/9-HP-add_ball('box1',)-1.0 13-RP-add_sticker('box1',)-1.0 27-HP-send('box1',)-1.0 85-RP-add_ball('box2',)-1.0 94-HP-get_more()-1.0 98-RP-add_sticker('box2',)-1.0 99-HP-back_refill()-1.0 104-RP-add_ball('box3',)-1.0 111-HP-send('box2',)-1.0 115-RP-add_ball('box3',)-1.0 118-HP-WAIT[]-2.0 122-RP-add_sticker('box3',)-1.0 127-HP-send('box3',)-1.0 128-RP-IDLE[]-0.0
